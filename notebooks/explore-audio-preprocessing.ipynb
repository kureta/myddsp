{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import einops\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "from torch.nn import functional as F\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "import myddsp.constants as C\n",
    "import myddsp.preprocessors as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49e139",
   "metadata": {},
   "source": [
    "## Load example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = librosa.load(\"../data/test/samples/violin-1.wav\", sr=48000, mono=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796eb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.from_numpy(y)\n",
    "yy = yy.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d314355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(y, rate=48000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120547a7",
   "metadata": {},
   "source": [
    "## Explore loudness calculation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = pre.Loudness()\n",
    "ld = ld.eval()\n",
    "for p in ld.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a07dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    amps = ld(yy).flatten().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b62bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = amps[amps >= -70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df9b8e",
   "metadata": {},
   "source": [
    "## Explore pitch calculation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "\n",
    "from myddsp.crepe import load_model\n",
    "from myddsp.preprocessors import get_centered_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F0(nn.Module):\n",
    "    def __init__(self, capacity: str = \"full\"):\n",
    "        super().__init__()\n",
    "        self.model = load_model(capacity)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.mean(1)\n",
    "        frames = get_centered_frames(x, C.CREPE_N_FFT, C.CREPE_HOP_LENGTH)\n",
    "\n",
    "        b, n, f = frames.shape\n",
    "        batched = einops.rearrange(frames, \"b n f -> (b f) n\")\n",
    "        zeroed = batched - batched.mean(dim=1, keepdim=True)\n",
    "        normalized = zeroed / zeroed.std(dim=1, keepdim=True)\n",
    "\n",
    "        activations = self.model(normalized)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d594a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crepe = F0(\"tiny\")\n",
    "crepe = crepe.eval()\n",
    "for p in crepe.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = Resample(48000, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    acti = crepe(rs(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f340cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(acti[amps >= -70, :].T, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d361a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
